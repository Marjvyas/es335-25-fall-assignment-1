{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdef01e6",
   "metadata": {},
   "source": [
    "# Decision Tree Usage Demonstration\n",
    "\n",
    "This notebook demonstrates the usage of our custom Decision Tree implementation across all four combinations of input and output types:\n",
    "\n",
    "1. **Real Input & Real Output** (Regression)\n",
    "2. **Real Input & Discrete Output** (Classification)\n",
    "3. **Discrete Input & Discrete Output** (Classification)\n",
    "4. **Discrete Input & Real Output** (Regression)\n",
    "\n",
    "For each case, we'll test both Information Gain and Gini Index criteria and display the trees using graphviz visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd7a084",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d982c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The current code given is for the Assignment 1.\n",
    "You will be expected to use this to make trees for:\n",
    "> discrete input, discrete output\n",
    "> real input, real output\n",
    "> real input, discrete output\n",
    "> discrete input, real output\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tree.base import DecisionTree\n",
    "from metrics import *\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263b6f1",
   "metadata": {},
   "source": [
    "## Test Case 1: Real Input and Real Output (Regression)\n",
    "\n",
    "This case uses continuous features and continuous target values. We'll use RMSE and MAE as evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8cbd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST CASE 1: REAL INPUT AND REAL OUTPUT (REGRESSION)\n",
      "\n",
      "Data shape: X=(30, 5), y=(30,)\n",
      "data: \n",
      "           0         1         2         3         4    Target\n",
      "0   0.496714 -0.138264  0.647689  1.523030 -0.234153  0.250493\n",
      "1  -0.234137  1.579213  0.767435 -0.469474  0.542560  0.346448\n",
      "2  -0.463418 -0.465730  0.241962 -1.913280 -1.724918 -0.680025\n",
      "3  -0.562288 -1.012831  0.314247 -0.908024 -1.412304  0.232254\n",
      "4   1.465649 -0.225776  0.067528 -1.424748 -0.544383  0.293072\n",
      "5   0.110923 -1.150994  0.375698 -0.600639 -0.291694 -0.714351\n",
      "6  -0.601707  1.852278 -0.013497 -1.057711  0.822545  1.865775\n",
      "7  -1.220844  0.208864 -1.959670 -1.328186  0.196861  0.473833\n",
      "8   0.738467  0.171368 -0.115648 -0.301104 -1.478522 -1.191303\n",
      "9  -0.719844 -0.460639  1.057122  0.343618 -1.763040  0.656554\n",
      "10  0.324084 -0.385082 -0.676922  0.611676  1.031000 -0.974682\n",
      "11  0.931280 -0.839218 -0.309212  0.331263  0.975545  0.787085\n",
      "12 -0.479174 -0.185659 -1.106335 -1.196207  0.812526  1.158596\n",
      "13  1.356240 -0.072010  1.003533  0.361636 -0.645120 -0.820682\n",
      "14  0.361396  1.538037 -0.035826  1.564644 -2.619745  0.963376\n",
      "15  0.821903  0.087047 -0.299007  0.091761 -1.987569  0.412781\n",
      "16 -0.219672  0.357113  1.477894 -0.518270 -0.808494  0.822060\n",
      "17 -0.501757  0.915402  0.328751 -0.529760  0.513267  1.896793\n",
      "18  0.097078  0.968645 -0.702053 -0.327662 -0.392108 -0.245388\n",
      "19 -1.463515  0.296120  0.261055  0.005113 -0.234587 -0.753736\n",
      "20 -1.415371 -0.420645 -0.342715 -0.802277 -0.161286 -0.889514\n",
      "21  0.404051  1.886186  0.174578  0.257550 -0.074446 -0.815810\n",
      "22 -1.918771 -0.026514  0.060230  2.463242 -0.192361 -0.077102\n",
      "23  0.301547 -0.034712 -1.168678  1.142823  0.751933  0.341152\n",
      "24  0.791032 -0.909387  1.402794 -1.401851  0.586857  0.276691\n",
      "25  2.190456 -0.990536 -0.566298  0.099651 -0.503476  0.827183\n",
      "26 -1.550663  0.068563 -1.062304  0.473592 -0.919424  0.013002\n",
      "27  1.549934 -0.783253 -0.322062  0.813517 -1.230864  1.453534\n",
      "28  0.227460  1.307143 -1.607483  0.184634  0.259883 -0.264657\n",
      "29  0.781823 -1.236951 -1.320457  0.521942  0.296985  2.720169\n",
      "\n",
      "Feature types: [dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64')]\n",
      "Target type: float64\n",
      "Target range: [-1.19, 2.72]\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"TEST CASE 1: REAL INPUT AND REAL OUTPUT (REGRESSION)\")\n",
    "print()\n",
    "\n",
    "# Generate data\n",
    "N = 30  # Number of samples\n",
    "P = 5   # Number of features\n",
    "X = pd.DataFrame(np.random.randn(N, P))\n",
    "y = pd.Series(np.random.randn(N))\n",
    "\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "y = y.rename(\"Target\")\n",
    "print(\"data: \")\n",
    "print(pd.concat([X, y], axis=1))\n",
    "print()\n",
    "print(f\"Feature types: {[X[col].dtype for col in X.columns]}\")\n",
    "print(f\"Target type: {y.dtype}\")\n",
    "print(f\"Target range: [{y.min():.2f}, {y.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "255ace14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with Information Gain ---\n",
      "Criteria: information_gain\n",
      "RMSE: 0.3601\n",
      "MAE: 0.2407\n",
      "\n",
      "Displaying graphical tree for information_gain...\n",
      "Error creating graph: 'DecisionTree' object has no attribute 'create_graph'\n",
      "Falling back to text display:\n",
      "Tree visualization already exists: tree_real_input_real_output_information_gain.png (skipping regeneration)\n",
      "\n",
      "Decision Tree Structure:\n",
      "==================================================\n",
      "Root: 1 ≤ -1.194 (samples: 30)\n",
      "│\n",
      "├─ value: 2.720 (samples: 1)\n",
      "│\n",
      "└─ 4 ≤ 0.387 (samples: 29)\n",
      "    ├─ 0 ≤ 1.508 (samples: 21)\n",
      "    │   ├─ 4 ≤ -1.744 (samples: 19)\n",
      "    │   │   ├─ 1 ≤ 0.813 (samples: 3)\n",
      "    │   │   │   ├─ value: 0.535 (samples: 2)\n",
      "    │   │   │   └─ value: 0.963 (samples: 1)\n",
      "    │   │   └─ 2 ≤ 1.241 (samples: 16)\n",
      "    │   │       ├─ value: -0.346 (samples: 15)\n",
      "    │   │       └─ value: 0.822 (samples: 1)\n",
      "    │   └─ 0 ≤ 1.870 (samples: 2)\n",
      "    │       ├─ value: 1.454 (samples: 1)\n",
      "    │       └─ value: 0.827 (samples: 1)\n",
      "    └─ 0 ≤ -0.357 (samples: 8)\n",
      "        ├─ 0 ≤ -0.490 (samples: 3)\n",
      "        │   ├─ 0 ≤ -0.552 (samples: 2)\n",
      "        │   │   ├─ value: 1.866 (samples: 1)\n",
      "        │   │   └─ value: 1.897 (samples: 1)\n",
      "        │   └─ value: 1.159 (samples: 1)\n",
      "        └─ 4 ≤ 1.003 (samples: 5)\n",
      "            ├─ 0 ≤ 0.861 (samples: 4)\n",
      "            │   ├─ value: 0.321 (samples: 3)\n",
      "            │   └─ value: 0.787 (samples: 1)\n",
      "            └─ value: -0.975 (samples: 1)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with Information Gain\n",
    "print(\"\\n--- Testing with Information Gain ---\")\n",
    "tree_ig = DecisionTree(criterion=\"information_gain\")\n",
    "tree_ig.fit(X, y)\n",
    "y_hat_ig = tree_ig.predict(X)\n",
    "\n",
    "print(\"Criteria: information_gain\")\n",
    "print(f\"RMSE: {rmse(y_hat_ig, y):.4f}\")\n",
    "print(f\"MAE: {mae(y_hat_ig, y):.4f}\")\n",
    "\n",
    "# Display tree visualization\n",
    "print(f\"\\nDisplaying graphical tree for information_gain...\")\n",
    "try:\n",
    "    graph = tree_ig.create_graph(\n",
    "        feature_names=[f'feature_{i}' for i in range(len(X.columns))]\n",
    "    )\n",
    "    if not graph:\n",
    "        print(\"Graphviz not available, falling back to text display:\")\n",
    "        tree_ig.plot()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating graph: {e}\")\n",
    "    print(\"Falling back to text display:\")\n",
    "    tree_ig.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b4084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with Gini Index ---\n",
      "Criteria: gini_index\n",
      "RMSE: 0.3601\n",
      "MAE: 0.2407\n",
      "\n",
      "Displaying graphical tree for gini_index...\n",
      "Error creating graph: 'DecisionTree' object has no attribute 'create_graph'\n",
      "Falling back to text display:\n",
      "Tree visualization saved as: tree_real_input_real_output_gini_index.png\n",
      "\n",
      "Decision Tree Structure:\n",
      "==================================================\n",
      "Root: 1 ≤ -1.194 (samples: 30)\n",
      "│\n",
      "├─ value: 2.720 (samples: 1)\n",
      "│\n",
      "└─ 4 ≤ 0.387 (samples: 29)\n",
      "    ├─ 0 ≤ 1.508 (samples: 21)\n",
      "    │   ├─ 4 ≤ -1.744 (samples: 19)\n",
      "    │   │   ├─ 1 ≤ 0.813 (samples: 3)\n",
      "    │   │   │   ├─ value: 0.535 (samples: 2)\n",
      "    │   │   │   └─ value: 0.963 (samples: 1)\n",
      "    │   │   └─ 2 ≤ 1.241 (samples: 16)\n",
      "    │   │       ├─ value: -0.346 (samples: 15)\n",
      "    │   │       └─ value: 0.822 (samples: 1)\n",
      "    │   └─ 0 ≤ 1.870 (samples: 2)\n",
      "    │       ├─ value: 1.454 (samples: 1)\n",
      "    │       └─ value: 0.827 (samples: 1)\n",
      "    └─ 0 ≤ -0.357 (samples: 8)\n",
      "        ├─ 0 ≤ -0.490 (samples: 3)\n",
      "        │   ├─ 0 ≤ -0.552 (samples: 2)\n",
      "        │   │   ├─ value: 1.866 (samples: 1)\n",
      "        │   │   └─ value: 1.897 (samples: 1)\n",
      "        │   └─ value: 1.159 (samples: 1)\n",
      "        └─ 4 ≤ 1.003 (samples: 5)\n",
      "            ├─ 0 ≤ 0.861 (samples: 4)\n",
      "            │   ├─ value: 0.321 (samples: 3)\n",
      "            │   └─ value: 0.787 (samples: 1)\n",
      "            └─ value: -0.975 (samples: 1)\n",
      "==================================================\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with Gini Index\n",
    "print(\"\\n--- Testing with Gini Index ---\")\n",
    "tree_gini = DecisionTree(criterion=\"gini_index\")\n",
    "tree_gini.fit(X, y)\n",
    "y_hat_gini = tree_gini.predict(X)\n",
    "\n",
    "print(\"Criteria: gini_index\")\n",
    "print(f\"RMSE: {rmse(y_hat_gini, y):.4f}\")\n",
    "print(f\"MAE: {mae(y_hat_gini, y):.4f}\")\n",
    "\n",
    "# Display tree visualization\n",
    "print(f\"\\nDisplaying graphical tree for gini_index...\")\n",
    "try:\n",
    "    graph = tree_gini.create_graph(\n",
    "        feature_names=[f'feature_{i}' for i in range(len(X.columns))]\n",
    "    )\n",
    "    if not graph:\n",
    "        print(\"Graphviz not available, falling back to text display:\")\n",
    "        tree_gini.plot()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating graph: {e}\")\n",
    "    print(\"Falling back to text display:\")\n",
    "    tree_gini.plot()\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace8b6ec",
   "metadata": {},
   "source": [
    "## Test Case 2: Real Input and Discrete Output (Classification)\n",
    "\n",
    "This case uses continuous features and categorical target values. We'll use accuracy, precision, and recall as evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b0990ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST CASE 2: REAL INPUT AND DISCRETE OUTPUT (CLASSIFICATION)\n",
      "\n",
      "data: \n",
      "           0         1         2         3         4 Target\n",
      "0   0.625667 -0.857158 -1.070892  0.482472 -0.223463      4\n",
      "1   0.714000  0.473238 -0.072829 -0.846794 -1.514847      4\n",
      "2  -0.446515  0.856399  0.214094 -1.245739  0.173181      1\n",
      "3   0.385317 -0.883857  0.153725  0.058209 -1.142970      1\n",
      "4   0.357787  0.560785  1.083051  1.053802 -1.377669      1\n",
      "5  -0.937825  0.515035  0.513786  0.515048  3.852731      4\n",
      "6   0.570891  1.135566  0.954002  0.651391 -0.315269      2\n",
      "7   0.758969 -0.772825 -0.236819 -0.485364  0.081874      4\n",
      "8   2.314659 -1.867265  0.686260 -1.612716 -0.471932      2\n",
      "9   1.088951  0.064280 -1.077745 -0.715304  0.679598      2\n",
      "10 -0.730367  0.216459  0.045572 -0.651600  2.143944      1\n",
      "11  0.633919 -2.025143  0.186454 -0.661786  0.852433      3\n",
      "12 -0.792521 -0.114736  0.504987  0.865755 -1.200296      0\n",
      "13 -0.334501 -0.474945 -0.653329  1.765454  0.404982      1\n",
      "14 -1.260884  0.917862  2.122156  1.032465 -1.519370      1\n",
      "15 -0.484234  1.266911 -0.707669  0.443819  0.774634      3\n",
      "16 -0.926930 -0.059525 -3.241267 -1.024388 -0.252568      0\n",
      "17 -1.247783  1.632411 -1.430141 -0.440044  0.130741      4\n",
      "18  1.441273 -1.435862  1.163164  0.010233 -0.981509      4\n",
      "19  0.462103  0.199060 -0.600217  0.069802 -0.385314      1\n",
      "20  0.113517  0.662131  1.586017 -1.237815  2.133033      0\n",
      "21 -1.952088 -0.151785  0.588317  0.280992 -0.622700      1\n",
      "22 -0.208122 -0.493001 -0.589365  0.849602  0.357015      2\n",
      "23 -0.692910  0.899600  0.307300  0.812862  0.629629      1\n",
      "24 -0.828995 -0.560181  0.747294  0.610370 -0.020902      1\n",
      "25  0.117327  1.277665 -0.591571  0.547097 -0.202193      4\n",
      "26 -0.217681  1.098777  0.825416  0.813510  1.305479      4\n",
      "27  0.021004  0.681953 -0.310267  0.324166 -0.130143      4\n",
      "28  0.096996  0.595157 -0.818221  2.092387 -1.006017      2\n",
      "29 -1.214189  1.158111  0.791663  0.624120  0.628346      4\n",
      "\n",
      "Data shape: X=(30, 5), y=(30,)\n",
      "Feature types: [dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64')]\n",
      "Target type: category\n",
      "Target classes: [0, 1, 2, 3, 4]\n",
      "Class distribution: {0: 3, 1: 10, 2: 5, 3: 2, 4: 10}\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"TEST CASE 2: REAL INPUT AND DISCRETE OUTPUT (CLASSIFICATION)\")\n",
    "print()\n",
    "\n",
    "# Generate data\n",
    "N = 30\n",
    "P = 5\n",
    "X = pd.DataFrame(np.random.randn(N, P))\n",
    "y = pd.Series(np.random.randint(P, size=N), dtype=\"category\")\n",
    "\n",
    "y = y.rename(\"Target\")\n",
    "print(\"data: \")\n",
    "print(pd.concat([X, y], axis=1))\n",
    "print()\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"Feature types: {[X[col].dtype for col in X.columns]}\")\n",
    "print(f\"Target type: {y.dtype}\")\n",
    "print(f\"Target classes: {sorted(y.unique())}\")\n",
    "print(f\"Class distribution: {y.value_counts().sort_index().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8afbe64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with Information Gain ---\n",
      "Criteria: information_gain\n",
      "Accuracy: 0.9000\n",
      "Precision (class 0): 1.0000\n",
      "Recall (class 0): 0.3333\n",
      "Precision (class 1): 0.8182\n",
      "Recall (class 1): 0.9000\n",
      "Precision (class 2): 0.8333\n",
      "Recall (class 2): 1.0000\n",
      "Precision (class 3): 1.0000\n",
      "Recall (class 3): 1.0000\n",
      "Precision (class 4): 1.0000\n",
      "Recall (class 4): 1.0000\n",
      "\n",
      "Displaying graphical tree for information_gain...\n",
      "Error creating graph: 'DecisionTree' object has no attribute 'create_graph'\n",
      "Falling back to text display:\n",
      "Tree visualization saved as: tree_real_input_discrete_output_information_gain.png\n",
      "\n",
      "Decision Tree Structure:\n",
      "==================================================\n",
      "Root: 0 ≤ 0.516 (samples: 30)\n",
      "│\n",
      "├─ 1 ≤ 1.008 (samples: 22)\n",
      "│   ├─ 2 ≤ -0.450 (samples: 17)\n",
      "│   │   ├─ 0 ≤ -0.631 (samples: 5)\n",
      "│   │   │   ├─ class: 0 (samples: 1)\n",
      "│   │   │   └─ 0 ≤ -0.271 (samples: 4)\n",
      "│   │   │       ├─ class: 1 (samples: 1)\n",
      "│   │   │       └─ class: 2 (samples: 3)\n",
      "│   │   └─ 2 ≤ -0.132 (samples: 12)\n",
      "│   │       ├─ class: 4 (samples: 1)\n",
      "│   │       └─ 4 ≤ 2.998 (samples: 11)\n",
      "│   │           ├─ class: 1 (samples: 10)\n",
      "│   │           └─ class: 4 (samples: 1)\n",
      "│   └─ 2 ≤ -0.650 (samples: 5)\n",
      "│       ├─ 0 ≤ -0.866 (samples: 2)\n",
      "│       │   ├─ class: 4 (samples: 1)\n",
      "│       │   └─ class: 3 (samples: 1)\n",
      "│       └─ class: 4 (samples: 3)\n",
      "│\n",
      "└─ 1 ≤ -1.946 (samples: 8)\n",
      "    ├─ class: 3 (samples: 1)\n",
      "    └─ 4 ≤ -0.727 (samples: 7)\n",
      "        ├─ class: 4 (samples: 2)\n",
      "        └─ 0 ≤ 0.924 (samples: 5)\n",
      "            ├─ 0 ≤ 0.598 (samples: 3)\n",
      "            │   ├─ class: 2 (samples: 1)\n",
      "            │   └─ class: 4 (samples: 2)\n",
      "            └─ class: 2 (samples: 2)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with Information Gain\n",
    "print(\"\\n--- Testing with Information Gain ---\")\n",
    "tree_ig = DecisionTree(criterion=\"information_gain\")\n",
    "tree_ig.fit(X, y)\n",
    "y_hat_ig = tree_ig.predict(X)\n",
    "\n",
    "print(\"Criteria: information_gain\")\n",
    "print(f\"Accuracy: {accuracy(y_hat_ig, y):.4f}\")\n",
    "for cls in sorted(y.unique()):\n",
    "    print(f\"Precision (class {cls}): {precision(y_hat_ig, y, cls):.4f}\")\n",
    "    print(f\"Recall (class {cls}): {recall(y_hat_ig, y, cls):.4f}\")\n",
    "\n",
    "# Display tree visualization\n",
    "print(f\"\\nDisplaying graphical tree for information_gain...\")\n",
    "try:\n",
    "    graph = tree_ig.create_graph(\n",
    "        feature_names=[f'feature_{i}' for i in range(len(X.columns))]\n",
    "    )\n",
    "    if not graph:\n",
    "        print(\"Graphviz not available, falling back to text display:\")\n",
    "        tree_ig.plot()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating graph: {e}\")\n",
    "    print(\"Falling back to text display:\")\n",
    "    tree_ig.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07467e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with Gini Index ---\n",
      "Criteria: gini_index\n",
      "Accuracy: 0.8667\n",
      "Precision (class 0): 1.0000\n",
      "Recall (class 0): 0.3333\n",
      "Precision (class 1): 0.7143\n",
      "Recall (class 1): 1.0000\n",
      "Precision (class 2): 1.0000\n",
      "Recall (class 2): 0.8000\n",
      "Precision (class 3): 1.0000\n",
      "Recall (class 3): 1.0000\n",
      "Precision (class 4): 1.0000\n",
      "Recall (class 4): 0.9000\n",
      "\n",
      "Displaying graphical tree for gini_index...\n",
      "Error creating graph: 'DecisionTree' object has no attribute 'create_graph'\n",
      "Falling back to text display:\n",
      "Tree visualization saved as: tree_real_input_discrete_output_gini_index.png\n",
      "\n",
      "Decision Tree Structure:\n",
      "==================================================\n",
      "Root: 0 ≤ 0.516 (samples: 30)\n",
      "│\n",
      "├─ 1 ≤ 1.008 (samples: 22)\n",
      "│   ├─ 2 ≤ -0.736 (samples: 17)\n",
      "│   │   ├─ 0 ≤ -0.415 (samples: 2)\n",
      "│   │   │   ├─ class: 0 (samples: 1)\n",
      "│   │   │   └─ class: 2 (samples: 1)\n",
      "│   │   └─ 4 ≤ 2.998 (samples: 15)\n",
      "│   │       ├─ 2 ≤ -0.132 (samples: 14)\n",
      "│   │       │   ├─ class: 1 (samples: 4)\n",
      "│   │       │   └─ class: 1 (samples: 10)\n",
      "│   │       └─ class: 4 (samples: 1)\n",
      "│   └─ 2 ≤ -0.650 (samples: 5)\n",
      "│       ├─ 0 ≤ -0.866 (samples: 2)\n",
      "│       │   ├─ class: 4 (samples: 1)\n",
      "│       │   └─ class: 3 (samples: 1)\n",
      "│       └─ class: 4 (samples: 3)\n",
      "│\n",
      "└─ 1 ≤ -1.946 (samples: 8)\n",
      "    ├─ class: 3 (samples: 1)\n",
      "    └─ 4 ≤ -0.727 (samples: 7)\n",
      "        ├─ class: 4 (samples: 2)\n",
      "        └─ 0 ≤ 0.924 (samples: 5)\n",
      "            ├─ 0 ≤ 0.598 (samples: 3)\n",
      "            │   ├─ class: 2 (samples: 1)\n",
      "            │   └─ class: 4 (samples: 2)\n",
      "            └─ class: 2 (samples: 2)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with Gini Index\n",
    "print(\"\\n--- Testing with Gini Index ---\")\n",
    "tree_gini = DecisionTree(criterion=\"gini_index\")\n",
    "tree_gini.fit(X, y)\n",
    "y_hat_gini = tree_gini.predict(X)\n",
    "\n",
    "print(\"Criteria: gini_index\")\n",
    "print(f\"Accuracy: {accuracy(y_hat_gini, y):.4f}\")\n",
    "for cls in sorted(y.unique()):\n",
    "    print(f\"Precision (class {cls}): {precision(y_hat_gini, y, cls):.4f}\")\n",
    "    print(f\"Recall (class {cls}): {recall(y_hat_gini, y, cls):.4f}\")\n",
    "\n",
    "# Display tree visualization\n",
    "print(f\"\\nDisplaying graphical tree for gini_index...\")\n",
    "try:\n",
    "    graph = tree_gini.create_graph(\n",
    "        feature_names=[f'feature_{i}' for i in range(len(X.columns))]\n",
    "    )\n",
    "    if not graph:\n",
    "        print(\"Graphviz not available, falling back to text display:\")\n",
    "        tree_gini.plot()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating graph: {e}\")\n",
    "    print(\"Falling back to text display:\")\n",
    "    tree_gini.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82d9fb",
   "metadata": {},
   "source": [
    "## Test Case 3: Discrete Input and Discrete Output (Classification)\n",
    "\n",
    "This case uses categorical features and categorical target values. We'll use accuracy, precision, and recall as evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edee49e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST CASE 3: DISCRETE INPUT AND DISCRETE OUTPUT (CLASSIFICATION)\n",
      "\n",
      "data: \n",
      "    0  1  2  3  4 Target\n",
      "0   0  3  3  0  4      0\n",
      "1   3  0  3  1  4      0\n",
      "2   0  0  4  1  4      4\n",
      "3   0  0  1  1  4      4\n",
      "4   4  4  3  2  1      1\n",
      "5   3  1  3  4  1      2\n",
      "6   3  3  1  4  2      2\n",
      "7   3  4  1  0  0      3\n",
      "8   2  4  3  0  4      1\n",
      "9   4  4  1  1  0      1\n",
      "10  3  4  3  0  0      1\n",
      "11  2  4  3  2  2      1\n",
      "12  1  2  4  4  4      2\n",
      "13  1  3  0  1  4      2\n",
      "14  2  4  3  0  3      1\n",
      "15  2  3  2  2  0      3\n",
      "16  4  2  0  2  0      0\n",
      "17  4  2  0  0  1      0\n",
      "18  1  3  0  4  3      3\n",
      "19  3  0  4  0  1      1\n",
      "20  1  1  3  1  1      2\n",
      "21  3  0  4  0  1      0\n",
      "22  3  0  3  2  2      4\n",
      "23  4  0  4  0  2      4\n",
      "24  0  4  4  4  1      3\n",
      "25  0  2  2  3  3      1\n",
      "26  2  0  4  0  0      0\n",
      "27  4  2  1  4  3      1\n",
      "28  3  3  2  4  4      0\n",
      "29  0  1  4  2  2      3\n",
      "\n",
      "Data shape: X=(30, 5), y=(30,)\n",
      "Feature types: [CategoricalDtype(categories=[0, 1, 2, 3, 4], ordered=False, categories_dtype=int32), CategoricalDtype(categories=[0, 1, 2, 3, 4], ordered=False, categories_dtype=int32), CategoricalDtype(categories=[0, 1, 2, 3, 4], ordered=False, categories_dtype=int32), CategoricalDtype(categories=[0, 1, 2, 3, 4], ordered=False, categories_dtype=int32), CategoricalDtype(categories=[0, 1, 2, 3, 4], ordered=False, categories_dtype=int32)]\n",
      "Target type: category\n",
      "Target classes: [0, 1, 2, 3, 4]\n",
      "Class distribution: {0: 7, 1: 9, 2: 5, 3: 5, 4: 4}\n",
      "Feature value ranges: [[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4]]\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"TEST CASE 3: DISCRETE INPUT AND DISCRETE OUTPUT (CLASSIFICATION)\")\n",
    "print()\n",
    "\n",
    "# Generate data\n",
    "N = 30\n",
    "P = 5\n",
    "X = pd.DataFrame({i: pd.Series(np.random.randint(P, size=N), dtype=\"category\") for i in range(5)})\n",
    "y = pd.Series(np.random.randint(P, size=N), dtype=\"category\")\n",
    "\n",
    "y = y.rename(\"Target\")\n",
    "print(\"data: \")\n",
    "print(pd.concat([X, y], axis=1))\n",
    "print()\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"Feature types: {[X[col].dtype for col in X.columns]}\")\n",
    "print(f\"Target type: {y.dtype}\")\n",
    "print(f\"Target classes: {sorted(y.unique())}\")\n",
    "print(f\"Class distribution: {y.value_counts().sort_index().to_dict()}\")\n",
    "print(f\"Feature value ranges: {[sorted(X[col].unique()) for col in X.columns]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc838fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with Information Gain ---\n",
      "Criteria: information_gain\n",
      "Accuracy: 0.4333\n",
      "Precision (class 0): 0.5000\n",
      "Recall (class 0): 0.4286\n",
      "Precision (class 1): 0.3636\n",
      "Recall (class 1): 0.8889\n",
      "Precision (class 2): 0.0000\n",
      "Recall (class 2): 0.0000\n",
      "Precision (class 3): 0.0000\n",
      "Recall (class 3): 0.0000\n",
      "Precision (class 4): 1.0000\n",
      "Recall (class 4): 0.5000\n",
      "\n",
      "Displaying graphical tree for information_gain...\n",
      "Error creating graph: 'DecisionTree' object has no attribute 'create_graph'\n",
      "Falling back to text display:\n",
      "Tree visualization already exists: tree_real_input_discrete_output_information_gain.png (skipping regeneration)\n",
      "\n",
      "Decision Tree Structure:\n",
      "==================================================\n",
      "Root: 1 ≤ 0.000 (samples: 30)\n",
      "│\n",
      "├─ 4 ≤ 1.000 (samples: 8)\n",
      "│   ├─ class: 0 (samples: 2)\n",
      "│   └─ 0 ≤ 2.000 (samples: 6)\n",
      "│       ├─ class: 0 (samples: 1)\n",
      "│       └─ 0 ≤ 3.000 (samples: 5)\n",
      "│           ├─ 3 ≤ 1.000 (samples: 2)\n",
      "│           │   ├─ class: 0 (samples: 1)\n",
      "│           │   └─ class: 4 (samples: 1)\n",
      "│           └─ class: 4 (samples: 3)\n",
      "│\n",
      "└─ 1 ≤ 4.000 (samples: 22)\n",
      "    ├─ 2 ≤ 3.000 (samples: 8)\n",
      "    │   ├─ class: 1 (samples: 5)\n",
      "    │   └─ 0 ≤ 4.000 (samples: 3)\n",
      "    │       ├─ class: 1 (samples: 1)\n",
      "    │       └─ class: 3 (samples: 2)\n",
      "    └─ 4 ≤ 3.000 (samples: 14)\n",
      "        ├─ 0 ≤ 1.000 (samples: 3)\n",
      "        │   ├─ class: 3 (samples: 1)\n",
      "        │   └─ class: 1 (samples: 2)\n",
      "        └─ 3 ≤ 2.000 (samples: 11)\n",
      "            ├─ 0 ≤ 4.000 (samples: 3)\n",
      "            │   ├─ class: 0 (samples: 1)\n",
      "            │   └─ class: 3 (samples: 2)\n",
      "            └─ 3 ≤ 0.000 (samples: 8)\n",
      "                ├─ class: 0 (samples: 2)\n",
      "                └─ class: 2 (samples: 6)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with Information Gain\n",
    "print(\"\\n--- Testing with Information Gain ---\")\n",
    "tree_ig = DecisionTree(criterion=\"information_gain\")\n",
    "tree_ig.fit(X, y)\n",
    "y_hat_ig = tree_ig.predict(X)\n",
    "\n",
    "print(\"Criteria: information_gain\")\n",
    "print(f\"Accuracy: {accuracy(y_hat_ig, y):.4f}\")\n",
    "for cls in sorted(y.unique()):\n",
    "    print(f\"Precision (class {cls}): {precision(y_hat_ig, y, cls):.4f}\")\n",
    "    print(f\"Recall (class {cls}): {recall(y_hat_ig, y, cls):.4f}\")\n",
    "\n",
    "# Display tree visualization\n",
    "print(f\"\\nDisplaying graphical tree for information_gain...\")\n",
    "try:\n",
    "    graph = tree_ig.create_graph(\n",
    "        feature_names=[f'feature_{i}' for i in range(len(X.columns))]\n",
    "    )\n",
    "    if not graph:\n",
    "        print(\"Graphviz not available, falling back to text display:\")\n",
    "        tree_ig.plot()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating graph: {e}\")\n",
    "    print(\"Falling back to text display:\")\n",
    "    tree_ig.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bf480eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with Gini Index ---\n",
      "Criteria: gini_index\n",
      "Accuracy: 0.3000\n",
      "Precision (class 0): 0.0000\n",
      "Recall (class 0): 0.0000\n",
      "Precision (class 1): 0.3000\n",
      "Recall (class 1): 1.0000\n",
      "Precision (class 2): 0.0000\n",
      "Recall (class 2): 0.0000\n",
      "Precision (class 3): 0.0000\n",
      "Recall (class 3): 0.0000\n",
      "Precision (class 4): 0.0000\n",
      "Recall (class 4): 0.0000\n",
      "\n",
      "Displaying graphical tree for gini_index...\n",
      "Error creating graph: 'DecisionTree' object has no attribute 'create_graph'\n",
      "Falling back to text display:\n",
      "Tree visualization already exists: tree_real_input_discrete_output_gini_index.png (skipping regeneration)\n",
      "\n",
      "Decision Tree Structure:\n",
      "==================================================\n",
      "Root: 1 ≤ 4.000 (samples: 30)\n",
      "│\n",
      "├─ 2 ≤ 3.000 (samples: 8)\n",
      "│   ├─ class: 1 (samples: 5)\n",
      "│   └─ 0 ≤ 4.000 (samples: 3)\n",
      "│       ├─ class: 1 (samples: 1)\n",
      "│       └─ class: 3 (samples: 2)\n",
      "│\n",
      "└─ 1 ≤ 0.000 (samples: 22)\n",
      "    ├─ 4 ≤ 1.000 (samples: 8)\n",
      "    │   ├─ class: 0 (samples: 2)\n",
      "    │   └─ 0 ≤ 2.000 (samples: 6)\n",
      "    │       ├─ class: 0 (samples: 1)\n",
      "    │       └─ 0 ≤ 3.000 (samples: 5)\n",
      "    │           ├─ class: 0 (samples: 2)\n",
      "    │           └─ class: 4 (samples: 3)\n",
      "    └─ 4 ≤ 3.000 (samples: 14)\n",
      "        ├─ 0 ≤ 1.000 (samples: 3)\n",
      "        │   ├─ class: 3 (samples: 1)\n",
      "        │   └─ class: 1 (samples: 2)\n",
      "        └─ 0 ≤ 1.000 (samples: 11)\n",
      "            ├─ class: 2 (samples: 3)\n",
      "            └─ 0 ≤ 3.000 (samples: 8)\n",
      "                ├─ class: 2 (samples: 3)\n",
      "                └─ class: 0 (samples: 5)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with Gini Index\n",
    "print(\"\\n--- Testing with Gini Index ---\")\n",
    "tree_gini = DecisionTree(criterion=\"gini_index\")\n",
    "tree_gini.fit(X, y)\n",
    "y_hat_gini = tree_gini.predict(X)\n",
    "\n",
    "print(\"Criteria: gini_index\")\n",
    "print(f\"Accuracy: {accuracy(y_hat_gini, y):.4f}\")\n",
    "for cls in sorted(y.unique()):\n",
    "    print(f\"Precision (class {cls}): {precision(y_hat_gini, y, cls):.4f}\")\n",
    "    print(f\"Recall (class {cls}): {recall(y_hat_gini, y, cls):.4f}\")\n",
    "\n",
    "# Display tree visualization\n",
    "print(f\"\\nDisplaying graphical tree for gini_index...\")\n",
    "try:\n",
    "    graph = tree_gini.create_graph(\n",
    "        feature_names=[f'feature_{i}' for i in range(len(X.columns))]\n",
    "    )\n",
    "    if not graph:\n",
    "        print(\"Graphviz not available, falling back to text display:\")\n",
    "        tree_gini.plot()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating graph: {e}\")\n",
    "    print(\"Falling back to text display:\")\n",
    "    tree_gini.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ec7e7",
   "metadata": {},
   "source": [
    "## Test Case 4: Discrete Input and Real Output (Regression)\n",
    "\n",
    "This case uses categorical features and continuous target values. We'll use RMSE and MAE as evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a1b0c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST CASE 4: DISCRETE INPUT AND REAL OUTPUT (REGRESSION)\n",
      "\n",
      "data: \n",
      "    0  1  2  3  4    Target\n",
      "0   3  4  2  1  0  1.006293\n",
      "1   4  0  2  0  2 -0.576892\n",
      "2   1  4  2  3  0  0.835692\n",
      "3   4  0  2  2  1 -1.129707\n",
      "4   1  3  3  1  2  0.529804\n",
      "5   4  1  4  0  1  1.441569\n",
      "6   2  1  1  4  2 -2.471645\n",
      "7   2  0  1  3  4 -0.796895\n",
      "8   2  1  2  1  3  0.577072\n",
      "9   2  4  2  1  4 -0.203045\n",
      "10  0  2  0  2  1  0.371146\n",
      "11  2  0  4  2  3 -0.603985\n",
      "12  3  1  3  4  2  0.086590\n",
      "13  3  0  1  4  3 -0.155677\n",
      "14  0  0  0  0  0  1.167782\n",
      "15  2  2  0  0  3  0.254421\n",
      "16  2  4  1  4  0  0.337603\n",
      "17  2  0  3  4  3 -0.411877\n",
      "18  4  1  0  3  0 -0.487606\n",
      "19  1  3  0  2  1 -0.432558\n",
      "20  4  0  4  0  4  0.394452\n",
      "21  1  0  3  2  2 -0.420984\n",
      "22  2  2  0  2  3  0.289775\n",
      "23  2  4  3  4  4  2.075401\n",
      "24  4  3  1  3  2  0.871125\n",
      "25  4  1  2  1  2 -0.326024\n",
      "26  1  3  0  3  0  1.201214\n",
      "27  3  1  4  3  1 -0.408075\n",
      "28  1  4  1  2  1 -2.038125\n",
      "29  4  1  3  3  4 -1.008086\n",
      "\n",
      "Data shape: X=(30, 5), y=(30,)\n",
      "Feature types: [CategoricalDtype(categories=[0, 1, 2, 3, 4], ordered=False, categories_dtype=int32), CategoricalDtype(categories=[0, 1, 2, 3, 4], ordered=False, categories_dtype=int32), CategoricalDtype(categories=[0, 1, 2, 3, 4], ordered=False, categories_dtype=int32), CategoricalDtype(categories=[0, 1, 2, 3, 4], ordered=False, categories_dtype=int32), CategoricalDtype(categories=[0, 1, 2, 3, 4], ordered=False, categories_dtype=int32)]\n",
      "Target type: float64\n",
      "Target range: [-2.47, 2.08]\n",
      "Feature value ranges: [[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4]]\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"TEST CASE 4: DISCRETE INPUT AND REAL OUTPUT (REGRESSION)\")\n",
    "print()\n",
    "\n",
    "# Generate data\n",
    "N = 30\n",
    "P = 5\n",
    "X = pd.DataFrame({i: pd.Series(np.random.randint(P, size=N), dtype=\"category\") for i in range(5)})\n",
    "y = pd.Series(np.random.randn(N))\n",
    "\n",
    "y = y.rename(\"Target\")\n",
    "print(\"data: \")\n",
    "print(pd.concat([X, y], axis=1))\n",
    "print()\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"Feature types: {[X[col].dtype for col in X.columns]}\")\n",
    "print(f\"Target type: {y.dtype}\")\n",
    "print(f\"Target range: [{y.min():.2f}, {y.max():.2f}]\")\n",
    "print(f\"Feature value ranges: {[sorted(X[col].unique()) for col in X.columns]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee4d55a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with Information Gain ---\n",
      "Criteria: information_gain\n",
      "RMSE: 1.8072\n",
      "MAE: 1.4146\n",
      "\n",
      "Displaying graphical tree for information_gain...\n",
      "Error creating graph: 'DecisionTree' object has no attribute 'create_graph'\n",
      "Falling back to text display:\n",
      "Tree visualization already exists: tree_real_input_real_output_information_gain.png (skipping regeneration)\n",
      "\n",
      "Decision Tree Structure:\n",
      "==================================================\n",
      "Root: 2 ≤ 1.000 (samples: 30)\n",
      "│\n",
      "├─ 1 ≤ 1.000 (samples: 6)\n",
      "│   ├─ value: -2.472 (samples: 1)\n",
      "│   └─ 0 ≤ 1.000 (samples: 5)\n",
      "│       ├─ value: -2.038 (samples: 1)\n",
      "│       └─ 1 ≤ 0.000 (samples: 4)\n",
      "│           ├─ 0 ≤ 2.000 (samples: 2)\n",
      "│           │   ├─ value: -0.797 (samples: 1)\n",
      "│           │   └─ value: -0.156 (samples: 1)\n",
      "│           └─ 0 ≤ 2.000 (samples: 2)\n",
      "│               ├─ value: 0.338 (samples: 1)\n",
      "│               └─ value: 0.871 (samples: 1)\n",
      "│\n",
      "└─ 1 ≤ 4.000 (samples: 24)\n",
      "    ├─ 2 ≤ 2.000 (samples: 4)\n",
      "    │   ├─ 0 ≤ 2.000 (samples: 3)\n",
      "    │   │   ├─ value: -0.203 (samples: 1)\n",
      "    │   │   └─ 0 ≤ 3.000 (samples: 2)\n",
      "    │   │       ├─ value: 1.006 (samples: 1)\n",
      "    │   │       └─ value: 0.836 (samples: 1)\n",
      "    │   └─ value: 2.075 (samples: 1)\n",
      "    └─ 3 ≤ 0.000 (samples: 20)\n",
      "        ├─ 2 ≤ 2.000 (samples: 5)\n",
      "        │   ├─ value: -0.577 (samples: 1)\n",
      "        │   └─ 1 ≤ 1.000 (samples: 4)\n",
      "        │       ├─ value: 1.442 (samples: 1)\n",
      "        │       └─ value: 0.606 (samples: 3)\n",
      "        └─ 0 ≤ 4.000 (samples: 15)\n",
      "            ├─ 3 ≤ 1.000 (samples: 4)\n",
      "            │   ├─ value: -0.326 (samples: 1)\n",
      "            │   └─ value: -0.875 (samples: 3)\n",
      "            └─ 4 ≤ 0.000 (samples: 11)\n",
      "                ├─ value: 1.201 (samples: 1)\n",
      "                └─ value: -0.042 (samples: 10)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with Information Gain\n",
    "print(\"\\n--- Testing with Information Gain ---\")\n",
    "tree_ig = DecisionTree(criterion=\"information_gain\")\n",
    "tree_ig.fit(X, y)\n",
    "y_hat_ig = tree_ig.predict(X)\n",
    "\n",
    "print(\"Criteria: information_gain\")\n",
    "print(f\"RMSE: {rmse(y_hat_ig, y):.4f}\")\n",
    "print(f\"MAE: {mae(y_hat_ig, y):.4f}\")\n",
    "\n",
    "# Display tree visualization\n",
    "print(f\"\\nDisplaying graphical tree for information_gain...\")\n",
    "try:\n",
    "    graph = tree_ig.create_graph(\n",
    "        feature_names=[f'feature_{i}' for i in range(len(X.columns))]\n",
    "    )\n",
    "    if not graph:\n",
    "        print(\"Graphviz not available, falling back to text display:\")\n",
    "        tree_ig.plot()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating graph: {e}\")\n",
    "    print(\"Falling back to text display:\")\n",
    "    tree_ig.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93a29265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with Gini Index ---\n",
      "Criteria: gini_index\n",
      "RMSE: 1.8072\n",
      "MAE: 1.4146\n",
      "\n",
      "Displaying graphical tree for gini_index...\n",
      "Error creating graph: 'DecisionTree' object has no attribute 'create_graph'\n",
      "Falling back to text display:\n",
      "Tree visualization already exists: tree_real_input_real_output_gini_index.png (skipping regeneration)\n",
      "\n",
      "Decision Tree Structure:\n",
      "==================================================\n",
      "Root: 2 ≤ 1.000 (samples: 30)\n",
      "│\n",
      "├─ 1 ≤ 1.000 (samples: 6)\n",
      "│   ├─ value: -2.472 (samples: 1)\n",
      "│   └─ 0 ≤ 1.000 (samples: 5)\n",
      "│       ├─ value: -2.038 (samples: 1)\n",
      "│       └─ 1 ≤ 0.000 (samples: 4)\n",
      "│           ├─ 0 ≤ 2.000 (samples: 2)\n",
      "│           │   ├─ value: -0.797 (samples: 1)\n",
      "│           │   └─ value: -0.156 (samples: 1)\n",
      "│           └─ 0 ≤ 2.000 (samples: 2)\n",
      "│               ├─ value: 0.338 (samples: 1)\n",
      "│               └─ value: 0.871 (samples: 1)\n",
      "│\n",
      "└─ 1 ≤ 4.000 (samples: 24)\n",
      "    ├─ 2 ≤ 2.000 (samples: 4)\n",
      "    │   ├─ 0 ≤ 2.000 (samples: 3)\n",
      "    │   │   ├─ value: -0.203 (samples: 1)\n",
      "    │   │   └─ 0 ≤ 3.000 (samples: 2)\n",
      "    │   │       ├─ value: 1.006 (samples: 1)\n",
      "    │   │       └─ value: 0.836 (samples: 1)\n",
      "    │   └─ value: 2.075 (samples: 1)\n",
      "    └─ 3 ≤ 0.000 (samples: 20)\n",
      "        ├─ 2 ≤ 2.000 (samples: 5)\n",
      "        │   ├─ value: -0.577 (samples: 1)\n",
      "        │   └─ 1 ≤ 1.000 (samples: 4)\n",
      "        │       ├─ value: 1.442 (samples: 1)\n",
      "        │       └─ value: 0.606 (samples: 3)\n",
      "        └─ 0 ≤ 4.000 (samples: 15)\n",
      "            ├─ 3 ≤ 1.000 (samples: 4)\n",
      "            │   ├─ value: -0.326 (samples: 1)\n",
      "            │   └─ value: -0.875 (samples: 3)\n",
      "            └─ 4 ≤ 0.000 (samples: 11)\n",
      "                ├─ value: 1.201 (samples: 1)\n",
      "                └─ value: -0.042 (samples: 10)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with Gini Index\n",
    "print(\"\\n--- Testing with Gini Index ---\")\n",
    "tree_gini = DecisionTree(criterion=\"gini_index\")\n",
    "tree_gini.fit(X, y)\n",
    "y_hat_gini = tree_gini.predict(X)\n",
    "\n",
    "print(\"Criteria: gini_index\")\n",
    "print(f\"RMSE: {rmse(y_hat_gini, y):.4f}\")\n",
    "print(f\"MAE: {mae(y_hat_gini, y):.4f}\")\n",
    "\n",
    "# Display tree visualization\n",
    "print(f\"\\nDisplaying graphical tree for gini_index...\")\n",
    "try:\n",
    "    graph = tree_gini.create_graph(\n",
    "        feature_names=[f'feature_{i}' for i in range(len(X.columns))]\n",
    "    )\n",
    "    if not graph:\n",
    "        print(\"Graphviz not available, falling back to text display:\")\n",
    "        tree_gini.plot()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating graph: {e}\")\n",
    "    print(\"Falling back to text display:\")\n",
    "    tree_gini.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af486c93",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the versatility of our Decision Tree implementation across all four combinations of input and output types:\n",
    "\n",
    "**Real Input & Real Output** - Regression with continuous features  \n",
    "**Real Input & Discrete Output** - Classification with continuous features  \n",
    "**Discrete Input & Discrete Output** - Classification with categorical features  \n",
    "**Discrete Input & Real Output** - Regression with categorical features  \n",
    "\n",
    "Each case supports both Information Gain and Gini Index splitting criteria, with automatic detection of regression vs classification problems and appropriate visualization using graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f70c4b1-731e-49f3-bf83-b8e2c11be4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
